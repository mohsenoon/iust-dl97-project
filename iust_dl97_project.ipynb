{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iust-dl97-project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOffrGEGtUcP",
        "colab_type": "text"
      },
      "source": [
        "# Train Network from Scratch for Speaker Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEGyvsiqSE0U",
        "colab_type": "text"
      },
      "source": [
        "##Download and Extract VoxCeleb1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ZqmIcGODKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbbd099f-6642-49a4-c30d-1f0fe984073d"
      },
      "source": [
        "! wget --user voxceleb1902 --password nx0bl2v2 http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partaa\n",
        "! wget --user voxceleb1902 --password nx0bl2v2 http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partab\n",
        "! wget --user voxceleb1902 --password nx0bl2v2 http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partac\n",
        "! wget --user voxceleb1902 --password nx0bl2v2 http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partad\n",
        "\n",
        "! wget --user voxceleb1902 --password nx0bl2v2 http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip\n",
        "\n",
        "! wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/data/vox1_dev_txt.zip  \n",
        "! wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/data/vox1_test_txt.zip\n",
        "\n",
        "! wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\n",
        "! wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\n",
        "  \n",
        "! cat vox1_dev* > vox1_dev_wav.zip\n",
        "! rm vox1_dev_wav_partaa vox1_dev_wav_partab vox1_dev_wav_partac vox1_dev_wav_partad\n",
        "! mkdir -p voxceleb1\n",
        "! mv *.zip voxceleb1\n",
        "! mv *.txt voxceleb1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-21 15:01:01--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partaa\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"VoxCeleb1\"\n",
            "Reusing existing connection to www.robots.ox.ac.uk:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10737418240 (10G)\n",
            "Saving to: ‘vox1_dev_wav_partaa’\n",
            "\n",
            "vox1_dev_wav_partaa 100%[===================>]  10.00G  27.8MB/s    in 6m 14s  \n",
            "\n",
            "2019-07-21 15:07:15 (27.4 MB/s) - ‘vox1_dev_wav_partaa’ saved [10737418240/10737418240]\n",
            "\n",
            "--2019-07-21 15:07:17--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partab\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"VoxCeleb1\"\n",
            "Reusing existing connection to www.robots.ox.ac.uk:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10737418240 (10G)\n",
            "Saving to: ‘vox1_dev_wav_partab’\n",
            "\n",
            "vox1_dev_wav_partab 100%[===================>]  10.00G  27.9MB/s    in 6m 6s   \n",
            "\n",
            "2019-07-21 15:13:23 (28.0 MB/s) - ‘vox1_dev_wav_partab’ saved [10737418240/10737418240]\n",
            "\n",
            "--2019-07-21 15:13:25--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partac\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"VoxCeleb1\"\n",
            "Reusing existing connection to www.robots.ox.ac.uk:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10737418240 (10G)\n",
            "Saving to: ‘vox1_dev_wav_partac’\n",
            "\n",
            "vox1_dev_wav_partac 100%[===================>]  10.00G  27.9MB/s    in 6m 6s   \n",
            "\n",
            "2019-07-21 15:19:31 (28.0 MB/s) - ‘vox1_dev_wav_partac’ saved [10737418240/10737418240]\n",
            "\n",
            "--2019-07-21 15:19:34--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partad\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"VoxCeleb1\"\n",
            "Reusing existing connection to www.robots.ox.ac.uk:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 384369463 (367M)\n",
            "Saving to: ‘vox1_dev_wav_partad’\n",
            "\n",
            "vox1_dev_wav_partad 100%[===================>] 366.56M  28.5MB/s    in 12s     \n",
            "\n",
            "2019-07-21 15:19:46 (31.0 MB/s) - ‘vox1_dev_wav_partad’ saved [384369463/384369463]\n",
            "\n",
            "--2019-07-21 15:19:48--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"VoxCeleb1\"\n",
            "Reusing existing connection to www.robots.ox.ac.uk:80.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1072793438 (1023M) [application/zip]\n",
            "Saving to: ‘vox1_test_wav.zip’\n",
            "\n",
            "vox1_test_wav.zip   100%[===================>]   1023M  28.1MB/s    in 35s     \n",
            "\n",
            "2019-07-21 15:20:24 (28.8 MB/s) - ‘vox1_test_wav.zip’ saved [1072793438/1072793438]\n",
            "\n",
            "--2019-07-21 15:20:27--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/data/vox1_dev_txt.zip\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139078084 (133M) [application/zip]\n",
            "Saving to: ‘vox1_dev_txt.zip’\n",
            "\n",
            "vox1_dev_txt.zip    100%[===================>] 132.63M  32.7MB/s    in 4.0s    \n",
            "\n",
            "2019-07-21 15:20:31 (33.4 MB/s) - ‘vox1_dev_txt.zip’ saved [139078084/139078084]\n",
            "\n",
            "--2019-07-21 15:20:34--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/data/vox1_test_txt.zip\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4568199 (4.4M) [application/zip]\n",
            "Saving to: ‘vox1_test_txt.zip’\n",
            "\n",
            "vox1_test_txt.zip   100%[===================>]   4.36M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-07-21 15:20:34 (33.8 MB/s) - ‘vox1_test_txt.zip’ saved [4568199/4568199]\n",
            "\n",
            "--2019-07-21 15:20:38--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4912512 (4.7M) [text/plain]\n",
            "Saving to: ‘iden_split.txt’\n",
            "\n",
            "iden_split.txt      100%[===================>]   4.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-07-21 15:20:38 (41.6 MB/s) - ‘iden_split.txt’ saved [4912512/4912512]\n",
            "\n",
            "--2019-07-21 15:20:42--  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2338640 (2.2M) [text/plain]\n",
            "Saving to: ‘veri_test.txt’\n",
            "\n",
            "veri_test.txt       100%[===================>]   2.23M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-07-21 15:20:42 (32.4 MB/s) - ‘veri_test.txt’ saved [2338640/2338640]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW7bg-7mSZYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "DATA_PATH = 'voxceleb1/'\n",
        "\n",
        "print('Starting to unpack vox1_dev_wav.zip')\n",
        "zip = zipfile.ZipFile(os.path.join(DATA_PATH, 'vox1_dev_wav.zip'), 'r')\n",
        "zip.extractall(DATA_PATH)\n",
        "zip.close()\n",
        "print('Done. Starting to unpack vox1_test_wav.zip')\n",
        "zip = zipfile.ZipFile(os.path.join(DATA_PATH, 'vox1_test_wav.zip'), 'r')\n",
        "zip.extractall(DATA_PATH)\n",
        "zip.close()\n",
        "print('Done. Starting to unpack vox1_dev_txt.zip')\n",
        "zip = zipfile.ZipFile(os.path.join(DATA_PATH, 'vox1_dev_txt.zip'), 'r')\n",
        "zip.extractall(DATA_PATH)\n",
        "zip.close()\n",
        "print('Done. Starting to unpack vox1_test_txt.zip')\n",
        "zip = zipfile.ZipFile(os.path.join(DATA_PATH, 'vox1_test_txt.zip'), 'r')\n",
        "zip.extractall(DATA_PATH)\n",
        "zip.close()\n",
        "print('Done.')\n",
        "\n",
        "os.remove(os.path.join(DATA_PATH, 'vox1_dev_wav.zip'))\n",
        "os.remove(os.path.join(DATA_PATH, 'vox1_test_wav.zip'))\n",
        "os.remove(os.path.join(DATA_PATH, 'vox1_dev_txt.zip'))\n",
        "os.remove(os.path.join(DATA_PATH, 'vox1_test_txt.zip'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3myIBQcd2sb",
        "colab_type": "text"
      },
      "source": [
        "##with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzmJGsBJsWKE",
        "colab_type": "code",
        "outputId": "f18275d3-fdaf-4522-c150-a40cfa9a430c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import Compose\n",
        "\n",
        "! pip install tensorboardX\n",
        "import tensorboardX\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # scipy throws future warnings on fft (known bug)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jalpyzbF_Coz",
        "colab_type": "text"
      },
      "source": [
        "###Read wav files and calculate spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otk5QT2vdLyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IdentificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, path, train, transform=None):\n",
        "        iden_split_path = os.path.join(path, 'iden_split.txt')\n",
        "        split = pd.read_table(iden_split_path, sep=' ', header=None, names=['phase', 'path'])\n",
        "        \n",
        "        if train:\n",
        "            phases = [1, 2]\n",
        "        \n",
        "        else:\n",
        "            phases = [3]\n",
        "            \n",
        "        mask = split['phase'].isin(phases)\n",
        "        self.dataset = split['path'][mask].reset_index(drop=True)\n",
        "        self.path = path\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # path\n",
        "        track_path = self.dataset[idx]\n",
        "        audio_path = os.path.join(self.path, 'wav', track_path)\n",
        "\n",
        "        # read .wav\n",
        "        rate, samples = wavfile.read(audio_path)\n",
        "        # extract label from path like id10003/L9_sh8msGV59/00001.txt\n",
        "        # subtracting 1 because PyTorch assumes that C_i in [0, 1251-1]\n",
        "        label = int(track_path.split('/')[0].replace('id1', '')) - 1\n",
        "\n",
        "        ## parameters\n",
        "        window = 'hamming'\n",
        "        # window width and step size\n",
        "        Tw = 25 # ms\n",
        "        Ts = 10 # ms\n",
        "        # frame duration (samples)\n",
        "        Nw = int(rate * Tw * 1e-3)\n",
        "        Ns = int(rate * (Tw - Ts) * 1e-3)\n",
        "        # overlapped duration (samples)\n",
        "        # 2 ** to the next pow of 2 of (Nw - 1)\n",
        "        nfft = 2 ** (Nw - 1).bit_length()\n",
        "        pre_emphasis = 0.97\n",
        "        \n",
        "        # preemphasis filter\n",
        "        samples = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
        "        \n",
        "        # removes DC component of the signal and add a small dither\n",
        "        samples = signal.lfilter([1, -1], [1, -0.99], samples)\n",
        "        dither = np.random.uniform(-1, 1, samples.shape)\n",
        "        spow = np.std(samples)\n",
        "        samples = samples + 1e-6 * spow * dither\n",
        "        \n",
        "        if self.train:\n",
        "            # segment selection\n",
        "            segment_len = 3 # sec\n",
        "            upper_bound = len(samples) - segment_len * rate\n",
        "            start = np.random.randint(0, upper_bound)\n",
        "            end = start + segment_len * rate\n",
        "            samples = samples[start:end]\n",
        "        \n",
        "        # spectogram\n",
        "        _, _, spec = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n",
        "                                        mode='magnitude', return_onesided=False)\n",
        "        \n",
        "        # just multiplying it by 1600 makes spectrograms in the paper and here \"the same\"\n",
        "        spec *= rate / 10\n",
        "        \n",
        "        if self.transform:\n",
        "            spec = self.transform(spec)\n",
        "            \n",
        "         \n",
        "        \n",
        "        \n",
        "        \n",
        "        _, _, spec_phase = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n",
        "                                                mode='phase', return_onesided=False)                \n",
        "        spec_phase[1:,:] = np.diff(spec_phase, axis=0)\n",
        "        spec_phase = spec_phase.reshape(1, spec_phase.shape[0], spec_phase.shape[1])\n",
        "        spec_phase = spec_phase.astype(np.float32)\n",
        "        spec_phase = torch.from_numpy(spec_phase)\n",
        "        spec_ = np.concatenate((spec, spec_phase), axis=0)    \n",
        "        \n",
        "        \n",
        "\n",
        "        return label, spec_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvWx0xYa_K-B",
        "colab_type": "text"
      },
      "source": [
        "###mean and variance normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yAG_7jrdPCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Normalize(object):\n",
        "    \"\"\"Normalizes voice spectrogram (mean-varience)\"\"\"\n",
        "    \n",
        "    def __call__(self, spec):\n",
        "        \n",
        "        # (Freq, Time)\n",
        "        # mean-variance normalization for every spectrogram (not batch-wise)\n",
        "        mu = spec.mean(axis=1).reshape(512, 1)\n",
        "        sigma = spec.std(axis=1).reshape(512, 1)\n",
        "        spec = (spec - mu) / sigma\n",
        "\n",
        "        return spec\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert spectogram to Tensor.\"\"\"\n",
        "    \n",
        "    def __call__(self, spec):\n",
        "        F, T = spec.shape\n",
        "        \n",
        "        # now specs are of size (Freq, Time) and 2D but has to be 3D (channel dim)\n",
        "        spec = spec.reshape(1, F, T)\n",
        "        \n",
        "        # make the ndarray to be of a proper type (was float64)\n",
        "        spec = spec.astype(np.float32)\n",
        "        \n",
        "        return torch.from_numpy(spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWIMNoKR_Omk",
        "colab_type": "text"
      },
      "source": [
        "###create model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuk24rZvdSXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VoiceNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(VoiceNet, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=96, kernel_size=7, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm2d(num_features=96)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn6 = nn.BatchNorm2d(num_features=4096)\n",
        "        self.bn7 = nn.BatchNorm1d(num_features=1024)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.mpool5 = nn.MaxPool2d(kernel_size=(5, 3), stride=(3, 2))\n",
        "        \n",
        "        # Conv2d with weights of size (H, 1) is identical to FC with H weights\n",
        "        self.fc6 = nn.Conv2d(in_channels=256, out_channels=4096, kernel_size=(9, 1))\n",
        "        self.fc7 = nn.Linear(in_features=4096, out_features=1024)\n",
        "        self.fc8 = nn.Linear(in_features=1024, out_features=num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.size()\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.mpool1(x)\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.mpool2(x) \n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.mpool5(x)\n",
        "        x = self.relu(self.bn6(self.fc6(x)))\n",
        "        \n",
        "        _, _, _, W = x.size()\n",
        "        self.apool6 = nn.AvgPool2d(kernel_size=(1, W))\n",
        "        x = self.apool6(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.bn7(self.fc7(x)))\n",
        "        x = self.fc8(x)\n",
        "        \n",
        "        # during training, there's no need for SoftMax because CELoss calculates it\n",
        "        if self.training:\n",
        "            return x\n",
        "        \n",
        "        else:\n",
        "            return self.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXsVV5Tz_cwD",
        "colab_type": "text"
      },
      "source": [
        "###set hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-s4Inc5dWKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_PATH = 'logs/VoxCeleb/rm_dc_n_dither'\n",
        "! mkdir -p logs/VoxCeleb/rm_dc_n_dither\n",
        "EPOCH_NUM = 30\n",
        "\n",
        "# in shared code B = 100 but PyTorch throws CUDA out of memory at B = 97 \n",
        "# though B=96 takes only 90.6% of the GPU Mem (bug?):\n",
        "# https://discuss.pytorch.org/t/lesser-memory-consumption-with-a-larger-batch-in-multi-gpu-setup/29087\n",
        "# B = 96\n",
        "# but when \n",
        "torch.backends.cudnn.deterministic = True\n",
        "# I can set B = 100\n",
        "B = 100\n",
        "\n",
        "WEIGHT_DECAY = 5e-4\n",
        "LR_INIT = 1e-2\n",
        "LR_LAST = 1e-4\n",
        "# lr scheduler parameter\n",
        "gamma = 10 ** (np.log10(LR_LAST / LR_INIT) / (EPOCH_NUM - 1))\n",
        "MOMENTUM = 0.9\n",
        "DEVICE = 'cuda:0'\n",
        "NUM_WORKERS = 4\n",
        "TBoard = tensorboardX.SummaryWriter(log_dir=LOG_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtRZxXJ0_mVI",
        "colab_type": "text"
      },
      "source": [
        "###create model and data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVTOfeZDdsDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = VoiceNet(num_classes=1251)\n",
        "net.to(DEVICE)\n",
        "\n",
        "transforms = Compose([\n",
        "    Normalize(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "trainset = IdentificationDataset(DATASET_PATH, train=True, transform=transforms)\n",
        "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=B, num_workers=NUM_WORKERS, shuffle=True)\n",
        "\n",
        "testset = IdentificationDataset(DATASET_PATH, train=False, transform=transforms)\n",
        "testsetloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=NUM_WORKERS*2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), LR_INIT, MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phjIuS1i_XSc",
        "colab_type": "text"
      },
      "source": [
        "###model info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzF3lwsuZR_6",
        "colab_type": "code",
        "outputId": "0c2f9f9b-fe16-49b2-e73c-e0112bcbf93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(net, input_size=(2, 512, 300))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 96, 254, 148]           9,504\n",
            "       BatchNorm2d-2         [-1, 96, 254, 148]             192\n",
            "              ReLU-3         [-1, 96, 254, 148]               0\n",
            "         MaxPool2d-4          [-1, 96, 126, 73]               0\n",
            "            Conv2d-5          [-1, 256, 62, 36]         614,656\n",
            "       BatchNorm2d-6          [-1, 256, 62, 36]             512\n",
            "              ReLU-7          [-1, 256, 62, 36]               0\n",
            "         MaxPool2d-8          [-1, 256, 30, 17]               0\n",
            "            Conv2d-9          [-1, 256, 30, 17]         590,080\n",
            "      BatchNorm2d-10          [-1, 256, 30, 17]             512\n",
            "             ReLU-11          [-1, 256, 30, 17]               0\n",
            "           Conv2d-12          [-1, 256, 30, 17]         590,080\n",
            "      BatchNorm2d-13          [-1, 256, 30, 17]             512\n",
            "             ReLU-14          [-1, 256, 30, 17]               0\n",
            "           Conv2d-15          [-1, 256, 30, 17]         590,080\n",
            "      BatchNorm2d-16          [-1, 256, 30, 17]             512\n",
            "             ReLU-17          [-1, 256, 30, 17]               0\n",
            "        MaxPool2d-18            [-1, 256, 9, 8]               0\n",
            "           Conv2d-19           [-1, 4096, 1, 8]       9,441,280\n",
            "      BatchNorm2d-20           [-1, 4096, 1, 8]           8,192\n",
            "             ReLU-21           [-1, 4096, 1, 8]               0\n",
            "           Linear-22                 [-1, 1024]       4,195,328\n",
            "      BatchNorm1d-23                 [-1, 1024]           2,048\n",
            "             ReLU-24                 [-1, 1024]               0\n",
            "           Linear-25                 [-1, 1251]       1,282,275\n",
            "================================================================\n",
            "Total params: 17,325,763\n",
            "Trainable params: 17,325,763\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.17\n",
            "Forward/backward pass size (MB): 113.30\n",
            "Params size (MB): 66.09\n",
            "Estimated Total Size (MB): 180.56\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enwTgQnu_rek",
        "colab_type": "text"
      },
      "source": [
        "###Training and calculate accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WjPvT8tesZZ",
        "colab_type": "code",
        "outputId": "9f2a848d-f6ef-460f-deac-9c8f35c2ac3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for epoch_num in range(EPOCH_NUM):\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    # train\n",
        "    net.train()\n",
        "    \n",
        "    for iter_num, (labels, specs) in tqdm(enumerate(trainsetloader)):\n",
        "        optimizer.zero_grad()\n",
        "        labels, specs = labels.to(DEVICE), specs.to(DEVICE)\n",
        "        scores = net(specs)\n",
        "        loss = criterion(scores, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # TBoard\n",
        "        step_num = epoch_num * len(trainsetloader) + iter_num\n",
        "        TBoard.add_scalar('Metrics/train_loss', loss.item(), step_num)\n",
        "        TBoard.add_scalar('Metrics/lr', lr_scheduler.get_lr()[0], step_num)\n",
        "        \n",
        "#         TBoard.add_scalar('weights/conv1', net.conv1.weight.mean(), step_num)\n",
        "#         TBoard.add_scalar('weights/conv5', net.conv5.weight.mean(), step_num)\n",
        "#         TBoard.add_scalar('weights/fc6', net.fc6.weight.mean(), step_num)\n",
        "#         TBoard.add_scalar('weights/fc7', net.fc7.weight.mean(), step_num)\n",
        "#         TBoard.add_scalar('weights/fc8', net.fc8.weight.mean(), step_num)\n",
        "#         TBoard.add_scalar('grads/conv1', net.conv1.weight.grad.mean(), step_num)\n",
        "#         TBoard.add_scalar('grads/conv5', net.conv5.weight.grad.mean(), step_num)\n",
        "#         TBoard.add_scalar('grads/fc6', net.fc6.weight.grad.mean(), step_num)\n",
        "#         TBoard.add_scalar('grads/fc7', net.fc7.weight.grad.mean(), step_num)\n",
        "#         TBoard.add_scalar('grads/fc8', net.fc8.weight.grad.mean(), step_num)\n",
        "\n",
        "    \n",
        "    # test\n",
        "    net.eval()\n",
        "    \n",
        "    top5_accuracy = 0\n",
        "    top1_accuracy = 0\n",
        "\n",
        "    for _, (label, spec) in tqdm(enumerate(testsetloader)):\n",
        "        label, spec = label.to(DEVICE), spec.to(DEVICE)\n",
        "        probs = net(spec)\n",
        "\n",
        "        # calculate Top-5 and Top-1 accuracy\n",
        "        pred_top5 = probs.topk(5)[1].view(5)\n",
        "\n",
        "        if label in pred_top5:\n",
        "            # increment top-5 accuracy\n",
        "            top5_accuracy += 1\n",
        "\n",
        "            if label == pred_top5[0]:\n",
        "                # increment top-1 accuracy\n",
        "                top1_accuracy += 1\n",
        "\n",
        "    top5_accuracy /= len(testsetloader)\n",
        "    top1_accuracy /= len(testsetloader)\n",
        "\n",
        "    TBoard.add_scalar('Metrics/test_top5', top5_accuracy, epoch_num)\n",
        "    TBoard.add_scalar('Metrics/test_top1', top1_accuracy, epoch_num)\n",
        "    \n",
        "    print('\\ntest_top5 =', round(100 * top5_accuracy, 2), '%')\n",
        "    print('test_top1 =', round(100 * top1_accuracy, 2), '%')\n",
        "        \n",
        "# when the training is finished save the model\n",
        "torch.save(net.state_dict(), os.path.join(LOG_PATH, 'model_snapshot.txt'))\n",
        "TBoard.close()\n",
        "print('top 1 accuracy @ the end: {}'.format(round(top1_accuracy, 3)))\n",
        "print('top 5 accuracy @ the end: {}'.format(round(top5_accuracy, 3)))\n",
        "print('loss @ the end: {}'.format(round(loss.item(), 3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1453it [1:13:42,  1.81s/it]\n",
            "8251it [10:21, 13.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "test_top5 = 3.56 %\n",
            "test_top1 = 3.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "526it [26:55,  3.18s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3BLgttW9DZm",
        "colab_type": "text"
      },
      "source": [
        "# Pre-Trained Model as Feature Extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrpJ4Of13y4T",
        "colab_type": "text"
      },
      "source": [
        "##with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwUZ939VnXVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8e422a8b-f1fc-4bb2-9297-66ae544a1134"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPl_qabGK_0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! wget https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/fa.tar.gz\n",
        "# ! cp fa.tar.gz drive/My\\ Drive/datasets/fa.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apjtPrqY0nOO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6a21e61-a0cc-4f74-871f-6ae6eb18a85f"
      },
      "source": [
        "! cp drive/My\\ Drive/datasets/fa.tar.gz fa.tar.gz\n",
        "! mkdir common_voice\n",
        "! tar -C common_voice -xf fa.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘common_voice’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST9OCSDqrSg-",
        "colab_type": "code",
        "outputId": "fa8f6329-83f8-4aaa-b96a-c64b7b92a1df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "! git clone https://github.com/mohsenoon/iust-dl97-project.git\n",
        "! apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "! pip install pyaudio"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'iust-dl97-project'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 39 (delta 4), reused 30 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.6/dist-packages (0.2.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik3u2xc_7JhB",
        "colab_type": "text"
      },
      "source": [
        "###for 1194 speakers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RruP61bg1V5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import collections\n",
        "\n",
        "with open('common_voice/validated.tsv', 'r') as val:\n",
        "  lines = val.readlines()\n",
        "  \n",
        "clients_id = []\n",
        "files_name = []\n",
        "mp3_name = []\n",
        "for x in lines[1:]:\n",
        "  clients_id.append(x.split()[0])\n",
        "  files_name.append(x.split()[1].replace('mp3','wav'))\n",
        "  mp3_name.append(x.split()[1])\n",
        "  \n",
        "import collections\n",
        "sample_per_speaker = 2\n",
        "spk_id = [item for item, count in collections.Counter(clients_id).items() if count >= sample_per_speaker]\n",
        "\n",
        "\n",
        "spk_index = []\n",
        "file_index = []\n",
        "mp3_index = []\n",
        "for i, sid in enumerate(spk_id):\n",
        "  idx = clients_id.index(sid)\n",
        "  [spk_index.append(i) for f in clients_id[idx : idx+sps]]\n",
        "  [file_index.append(os.path.join(DATA_PATH, f)) for f in files_name[idx : idx+sps]]\n",
        "  [mp3_index.append(os.path.join('common_voice/clips', f)) for f in mp3_name[idx : idx+sps]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKvHmqB9LNYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# mp3 to wav\n",
        "if not os.path.isdir('common_voice/wav'):\n",
        "  os.mkdir('common_voice/wav')\n",
        "for i, wav in enumerate(file_index):\n",
        "  os.system('ffmpeg -i {} -ar 16000 {}'.format(mp3_index[i], wav))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daU9GgWNMl3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('iust-dl97-project/cfg/enroll_list.csv', mode='w') as csv_file:\n",
        "    fieldnames = ['filename', 'speaker']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for i in range(0, len(file_index), 2):\n",
        "      writer.writerow({'filename': '../'+file_index[i], 'speaker': spk_index[i]})\n",
        "\n",
        "with open('iust-dl97-project/cfg/test_list.csv', mode='w') as csv_file:\n",
        "    fieldnames = ['filename', 'speaker']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for i in range(1, len(file_index), 2):\n",
        "      writer.writerow({'filename': '../'+file_index[i], 'speaker': spk_index[i]})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Cyy2OvrlA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62dfe47b-6d81-4b33-c996-c4c788b0cc9f"
      },
      "source": [
        "% cd iust-dl97-project\n",
        "! python scoring.py\n",
        "% cd .."
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/iust-dl97-project\n",
            "Using TensorFlow backend.\n",
            "Loading model weights from [model/weights.h5]....\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0721 14:41:17.353217 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0721 14:41:17.370271 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0721 14:41:17.397982 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0721 14:41:17.398170 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0721 14:41:17.398384 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-07-21 14:41:17.405777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-21 14:41:17.406050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71c08c0 executing computations on platform Host. Devices:\n",
            "2019-07-21 14:41:17.406093: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-21 14:41:17.409098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-21 14:41:17.515425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:41:17.515999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71c0c40 executing computations on platform CUDA. Devices:\n",
            "2019-07-21 14:41:17.516043: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-21 14:41:17.516352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:41:17.516760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-21 14:41:17.517167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-21 14:41:17.518865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-21 14:41:17.520389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-21 14:41:17.520754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-21 14:41:17.522789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-21 14:41:17.524356: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-21 14:41:17.529102: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-21 14:41:17.529309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:41:17.529811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:41:17.530213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-21 14:41:17.530290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-21 14:41:17.531585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-21 14:41:17.531620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-21 14:41:17.531657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-21 14:41:17.532044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:41:17.532527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:41:17.532916: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-21 14:41:17.532974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0721 14:41:18.013679 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0721 14:41:18.091634 140413200598912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 512, None, 1)      0         \n",
            "_________________________________________________________________\n",
            "pad1 (ZeroPadding2D)         (None, 514, None, 1)      0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 254, None, 96)     4800      \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 254, None, 96)     384       \n",
            "_________________________________________________________________\n",
            "relu1 (Activation)           (None, 254, None, 96)     0         \n",
            "_________________________________________________________________\n",
            "mpool1 (MaxPooling2D)        (None, 126, None, 96)     0         \n",
            "_________________________________________________________________\n",
            "pad2 (ZeroPadding2D)         (None, 128, None, 96)     0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 62, None, 256)     614656    \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 62, None, 256)     1024      \n",
            "_________________________________________________________________\n",
            "relu2 (Activation)           (None, 62, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "mpool2 (MaxPooling2D)        (None, 30, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "pad3 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 30, None, 384)     885120    \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 30, None, 384)     1536      \n",
            "_________________________________________________________________\n",
            "relu3 (Activation)           (None, 30, None, 384)     0         \n",
            "_________________________________________________________________\n",
            "pad4 (ZeroPadding2D)         (None, 32, None, 384)     0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 30, None, 256)     884992    \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
            "_________________________________________________________________\n",
            "relu4 (Activation)           (None, 30, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "pad5 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 30, None, 256)     590080    \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
            "_________________________________________________________________\n",
            "relu5 (Activation)           (None, 30, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "mpool5 (MaxPooling2D)        (None, 9, None, 256)      0         \n",
            "_________________________________________________________________\n",
            "pad6 (ZeroPadding2D)         (None, 9, None, 256)      0         \n",
            "_________________________________________________________________\n",
            "fc6 (Conv2D)                 (None, 1, None, 4096)     9441280   \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 1, None, 4096)     16384     \n",
            "_________________________________________________________________\n",
            "relu6 (Activation)           (None, 1, None, 4096)     0         \n",
            "_________________________________________________________________\n",
            "gapool6 (GlobalAveragePoolin (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "reshape6 (Reshape)           (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "pad7 (ZeroPadding2D)         (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "fc7 (Conv2D)                 (None, 1, 1, 1024)        4195328   \n",
            "_________________________________________________________________\n",
            "bn7 (BatchNormalization)     (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "relu7 (Activation)           (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "norm (Lambda)                (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "fc8 (Conv2D)                 (None, 1, 1, 1024)        1049600   \n",
            "=================================================================\n",
            "Total params: 17,691,328\n",
            "Trainable params: 17,678,592\n",
            "Non-trainable params: 12,736\n",
            "_________________________________________________________________\n",
            "Processing enroll samples....\n",
            "2019-07-21 14:48:19.926975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "Processing test samples....\n",
            "Comparing test samples against enroll samples....\n",
            "Writing outputs to [res/results.csv]....\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N21nTJbQ-m9-"
      },
      "source": [
        "####Accuracy Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3e1a0980-2919-46ea-e2b5-1b9a910afa99",
        "id": "Yv7Yx6k8-m9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('iust-dl97-project/res/results.csv')\n",
        "\n",
        "accuracy = sum(df['correct']) / len(df['correct'])\n",
        "\n",
        "print('Accuracy =', accuracy * 100, '%')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 30.569514237855945 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzr_hqSm7bnK",
        "colab_type": "text"
      },
      "source": [
        "###for 196 speakers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXhSIZEv8uOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e403cee-19e9-4efd-ea77-3beae4370e60"
      },
      "source": [
        "import os\n",
        "import collections\n",
        "\n",
        "with open('common_voice/validated.tsv', 'r') as val:\n",
        "  lines = val.readlines()\n",
        "  \n",
        "clients_id = []\n",
        "files_name = []\n",
        "mp3_name = []\n",
        "for x in lines[1:]:\n",
        "  clients_id.append(x.split()[0])\n",
        "  files_name.append(x.split()[1].replace('mp3','wav'))\n",
        "  mp3_name.append(x.split()[1])\n",
        "  \n",
        "import collections\n",
        "sample_per_speaker = 40\n",
        "spk_id = [item for item, count in collections.Counter(clients_id).items() if count >= sample_per_speaker]\n",
        "\n",
        "print('number of speakers =', len(spk_id))\n",
        "\n",
        "spk_index = []\n",
        "file_index = []\n",
        "mp3_index = []\n",
        "for i, sid in enumerate(spk_id):\n",
        "  idx = clients_id.index(sid)\n",
        "  [spk_index.append(i) for f in clients_id[idx : idx+sps]]\n",
        "  [file_index.append(os.path.join(DATA_PATH, f)) for f in files_name[idx : idx+sps]]\n",
        "  [mp3_index.append(os.path.join('common_voice/clips', f)) for f in mp3_name[idx : idx+sps]]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of speakers = 196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY6_o0-p7kRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('iust-dl97-project/cfg/enroll_list.csv', mode='w') as csv_file:\n",
        "    fieldnames = ['filename', 'speaker']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for i in range(0, len(file_index), 2):\n",
        "      writer.writerow({'filename': '../'+file_index[i], 'speaker': spk_index[i]})\n",
        "\n",
        "with open('iust-dl97-project/cfg/test_list.csv', mode='w') as csv_file:\n",
        "    fieldnames = ['filename', 'speaker']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for i in range(1, len(file_index), 2):\n",
        "      writer.writerow({'filename': '../'+file_index[i], 'speaker': spk_index[i]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGqCR4Ky7neQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8fed2bc-d023-4ba3-c183-d1b04d3f163c"
      },
      "source": [
        "% cd iust-dl97-project\n",
        "! python scoring.py\n",
        "% cd .."
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/iust-dl97-project\n",
            "Using TensorFlow backend.\n",
            "Loading model weights from [model/weights.h5]....\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0721 14:33:04.827537 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0721 14:33:04.844577 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0721 14:33:04.872748 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0721 14:33:04.872946 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0721 14:33:04.873126 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-07-21 14:33:04.878503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-07-21 14:33:04.878760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x75348c0 executing computations on platform Host. Devices:\n",
            "2019-07-21 14:33:04.878799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-21 14:33:04.881063: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-21 14:33:04.987022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:33:04.987641: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7534c40 executing computations on platform CUDA. Devices:\n",
            "2019-07-21 14:33:04.987675: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-07-21 14:33:04.987943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:33:04.988391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-21 14:33:04.988799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-21 14:33:04.990374: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-21 14:33:04.992101: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-21 14:33:04.992504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-21 14:33:04.994347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-21 14:33:04.995823: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-21 14:33:05.000030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-21 14:33:05.000178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:33:05.000655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:33:05.001015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-21 14:33:05.001095: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-21 14:33:05.002646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-21 14:33:05.002697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-21 14:33:05.002715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-21 14:33:05.003148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:33:05.003680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-21 14:33:05.004053: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-21 14:33:05.004114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0721 14:33:05.498905 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0721 14:33:05.576960 140481328191360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "2019-07-21 14:33:06.733841: W tensorflow/core/framework/allocator.cc:107] Allocation of 37748736 exceeds 10% of system memory.\n",
            "2019-07-21 14:33:06.733986: W tensorflow/core/framework/allocator.cc:107] Allocation of 16777216 exceeds 10% of system memory.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 512, None, 1)      0         \n",
            "_________________________________________________________________\n",
            "pad1 (ZeroPadding2D)         (None, 514, None, 1)      0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 254, None, 96)     4800      \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 254, None, 96)     384       \n",
            "_________________________________________________________________\n",
            "relu1 (Activation)           (None, 254, None, 96)     0         \n",
            "_________________________________________________________________\n",
            "mpool1 (MaxPooling2D)        (None, 126, None, 96)     0         \n",
            "_________________________________________________________________\n",
            "pad2 (ZeroPadding2D)         (None, 128, None, 96)     0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 62, None, 256)     614656    \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 62, None, 256)     1024      \n",
            "_________________________________________________________________\n",
            "relu2 (Activation)           (None, 62, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "mpool2 (MaxPooling2D)        (None, 30, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "pad3 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 30, None, 384)     885120    \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 30, None, 384)     1536      \n",
            "_________________________________________________________________\n",
            "relu3 (Activation)           (None, 30, None, 384)     0         \n",
            "_________________________________________________________________\n",
            "pad4 (ZeroPadding2D)         (None, 32, None, 384)     0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 30, None, 256)     884992    \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
            "_________________________________________________________________\n",
            "relu4 (Activation)           (None, 30, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "pad5 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 30, None, 256)     590080    \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
            "_________________________________________________________________\n",
            "relu5 (Activation)           (None, 30, None, 256)     0         \n",
            "_________________________________________________________________\n",
            "mpool5 (MaxPooling2D)        (None, 9, None, 256)      0         \n",
            "_________________________________________________________________\n",
            "pad6 (ZeroPadding2D)         (None, 9, None, 256)      0         \n",
            "_________________________________________________________________\n",
            "fc6 (Conv2D)                 (None, 1, None, 4096)     9441280   \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 1, None, 4096)     16384     \n",
            "_________________________________________________________________\n",
            "relu6 (Activation)           (None, 1, None, 4096)     0         \n",
            "_________________________________________________________________\n",
            "gapool6 (GlobalAveragePoolin (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "reshape6 (Reshape)           (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "pad7 (ZeroPadding2D)         (None, 1, 1, 4096)        0         \n",
            "_________________________________________________________________\n",
            "fc7 (Conv2D)                 (None, 1, 1, 1024)        4195328   \n",
            "_________________________________________________________________\n",
            "bn7 (BatchNormalization)     (None, 1, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "relu7 (Activation)           (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "norm (Lambda)                (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "fc8 (Conv2D)                 (None, 1, 1, 1024)        1049600   \n",
            "=================================================================\n",
            "Total params: 17,691,328\n",
            "Trainable params: 17,678,592\n",
            "Non-trainable params: 12,736\n",
            "_________________________________________________________________\n",
            "Processing enroll samples....\n",
            "2019-07-21 14:33:50.492774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "Processing test samples....\n",
            "Comparing test samples against enroll samples....\n",
            "Writing outputs to [res/results.csv]....\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWdrSB259WPv",
        "colab_type": "text"
      },
      "source": [
        "####Accuracy Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om-9I0zd9Rbh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adc2c299-281e-447a-c564-717eff111372"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('iust-dl97-project/res/results.csv')\n",
        "\n",
        "accuracy = sum(df['correct']) / len(df['correct'])\n",
        "\n",
        "print('Accuracy =', accuracy * 100, '%')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 50.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}